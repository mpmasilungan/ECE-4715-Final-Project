!python --version
!pip install tensorflow
print("done")

import pandas as pd

# Read the Excel file into a DataFrame
df = pd.read_csv("C:\\Users\\tropi\\Documents\\TFProj\\data.csv")

# Print the first 5 rows of the DataFrame
print(df.head()) 

copy_url = []
copy_html = []
copy_status = []
legitimate_counter = 0
phishing_counter = 0
total_count = 0

for i in range(length_url):
    copy_url.append(df.URL[i])
    copy_html.append(df.Content[i])
    copy_status.append(df.status[i])
    if copy_status[i] == "legitimate":
        legitimate_counter += 1
    else:
        phishing_counter += 1

print(legitimate_counter)
print(phishing_counter)
print(legitimate_counter + phishing_counter)

binary_html = []
error_index = []

### HTML TO BINARY
for i in range(length_url):
    try:
        res = ''.join(format(i, '08b') for i in bytearray(copy_html[i], encoding ='utf-8'))
        binary_html.append(res)
        print(f"Finished {i + 1} / 5489")
    except (TypeError):
        print(f"Error at {i + 1}")
        error_index.append(i + 1)

### BINARY VISUALIZATION ATTEMPT 1

from PIL import Image
import numpy as np
import math

binary_images = []

def binary_to_image(binary_string, width, height):
    required_length = width * height * 24  # Each pixel needs 24 bits (RGB)
    
    img_data = np.zeros((height, width, 3), dtype=np.uint8)
    
    idx = 0
    for row in range(height):
        for col in range(width):
            try:
                r = int(binary_string[idx:idx+8], 2)  # Red channel
                g = int(binary_string[idx+8:idx+16], 2)  # Green channel
                b = int(binary_string[idx+16:idx+24], 2)  # Blue channel
            except ValueError:
                raise ValueError(f"Failed to parse binary data at index {idx}. The binary string is likely malformed.")
            
            img_data[row, col] = [r, g, b]
            idx += 24

    img = Image.fromarray(img_data)
    
    return img
    
for i in range(len(binary_html)):
    binary_string = binary_html[i]
    width = int(math.sqrt(len(binary_string))/12) # Image width
    height = int(math.sqrt(len(binary_string))/12)  # Image height

    # Convert binary string to image
    img = binary_to_image(binary_string, width, height)

    # Resize the image
    new_size = (28, 28
    resized_image = img.resize(new_size)

    binary_images.append(resized_image)

    print(f"Finished {i + 1}")

### CREATING LABELS AS BINARY FOR EACH IMAGE

#phishing = 0; legitimate = 1
status_as_binary = []

for i in range(len(copy_status)):
    if copy_status[i] == "legitimate":
        status_as_binary.append(1)
    else:
        status_as_binary.append(0)

### COPYING TO ANOTHER ARRAY TO PRESERVE ORIGINAL
copy_images = []
copy_status_binary = []

for i in range(len(binary_images)):
    copy_images.append(binary_images[i])

for i in range(len(status_as_binary)):
    copy_status_binary.append(status_as_binary[i])

### LABEL CREATION FOR TENSORFLOW
import tensorflow as tf
import os
from tensorflow.keras.preprocessing import image
import numpy as np
from sklearn.model_selection import train_test_split

images = np.array(copy_images)
labels = np.array(copy_status_binary)

print("Shape of images:", images.shape)
print("Shape of labels:", labels.shape)

print("Done Creating Arrays")

dataset = tf.data.Dataset.from_tensor_slices((images, labels))

print("Done Creating Dataset")

for img, label in dataset:
    print(f"Image shape: {img.shape}, Label: {label}")

train_images, test_images, train_labels, test_labels = train_test_split(
    images, labels, test_size=0.2, random_state=42)

# Check the shapes of the split datasets
print(f"Train Images Shape: {train_images.shape}")
print(f"Test Images Shape: {test_images.shape}")
print(f"Train Labels Shape: {train_labels.shape}")
print(f"Test Labels Shape: {test_labels.shape}")

### TRAINING MODEL USING TENSORFLOW

training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))
testing_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))

batch_size = 32
training_dataset = training_dataset.shuffle(buffer_size=1000).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)

# Example Model (Simple CNN)
model = tf.keras.Sequential([
    tf.keras.layers.InputLayer(input_shape=(28, 28, 3)),
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer (binary classification)
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model on the dataset
model.fit(training_dataset, epochs=100)

### TESTING MODEL

test_images_resized = tf.image.resize(test_images, (28, 28))

# Ensure the data type is correct (float32)
test_images_resized = tf.cast(test_images_resized, tf.float32)

# Normalize if necessary
test_images_resized /= 255.0  # Normalize to the range [0, 1] if required

# Create the test dataset
test_dataset = tf.data.Dataset.from_tensor_slices((test_images_resized, test_labels))

# Batch the dataset
test_dataset = test_dataset.batch(32)

# Now evaluate the model
test_loss, test_accuracy = model.evaluate(test_dataset)

print(f"Test Loss: {test_loss}")
print(f"Test Accuracy: {test_accuracy}")
